# -*- coding: utf-8 -*-
"""(Preprocessing)Brain_Stroke_Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HrKAZdS3rp_XvzkzXdHOpNNjR10AKvys
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import os
import sys
import glob
import cv2
import scipy.ndimage
import skimage.filters
import skimage.transform
import nibabel as nib
import timeit
from tqdm.notebook import tqdm

# %matplotlib inline

drive_dir = '/content/drive/My Drive'
basedir = os.path.join( drive_dir, 'ATLAS_R1.1' )
basedir

path = glob.glob( basedir + '/*/*/*')

img_size = 128

def HistogramEqualization( image, number_bins=256 ):
    image_histogram, bins = np.histogram(image.flatten(), number_bins, density=True)
    cdf = image_histogram.cumsum() # cumulative distribution function
    cdf = 255 * cdf / cdf[-1] # normalize
    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)
    image_equalized = image_equalized.reshape( image.shape )
    return image_equalized.astype( np.float32 )

def median( img, size=3 ):
    arr =  scipy.ndimage.median_filter( img, size = size )
    return arr

def normalize( arr ):
    a = arr - arr.min()
    b = arr.max() - arr.min()
    return a / b

def cut_shape( arr ):
    return arr[25:175, 25:210, 55:125]

def CLAHE( arr ):
    clahe = cv2.createCLAHE( clipLimit=2.0, tileGridSize=(8,8) )
    arr = clahe.apply( arr ) 
    return arr

def preprocessing_all( arr ):
    arr = cut_shape( arr )
    arr = arr.transpose( ( 2, 1, 0 ) )
    arr = skimage.transform.resize( arr, ( img_size, img_size, img_size ) )
    return arr
    
def preprocessing_mri( arr ):
    #arr = HistogramEqualization( arr )
    """ Adaptive Histogram Equalization """
    clahe = cv2.createCLAHE( clipLimit=2.0, tileGridSize=(8,8) ) 
    arr = clahe.apply( arr.astype( np.uint16 ) )
    arr = arr.astype( np.float32 )
    arr = normalize( arr )
    arr = cv2.addWeighted ( arr,4, cv2.GaussianBlur( arr, ( 0, 0 ), img_size / 10 ), -4 , 128 )
    return arr.astype( np.float32 )

"""# Load All data in 2 arrays "faces, lesions"

# Total 229 Patients

    Train: 189 patients
    Validation: 9 patients
    Test: 31 patients  "Update Use The last 2030 instead of all 31 patient"
"""

train_size = 189
validation_size = 9
test_size = 31

train_x, train_y = [], []
val_x, val_y = [], []
test_x, test_y = [], []

for idx, path in tqdm( enumerate( path ) ):

    """ store faces """
    arr = glob.glob( f'{path}/*deface*' )
    arr = nib.load( arr[0] ).get_fdata()
    arr = preprocessing_all( arr )

    if idx < train_size:
        train_x.append( arr )
    elif idx < validation_size + train_size:
        val_x.append( arr )
    else:
        test_x.append( arr )

    """ store lesions """
    lesions = glob.glob( f'{path}/*LesionSmooth*' )
    # if mri has multiple lesions: apply Combine_Lesions
    if len( lesions ) > 1: 
        lesions = [ nib.load( i ).get_fdata() for i in lesions ]
        arr = np.logical_or.reduce( lesions )
    # if mri has single lesion
    elif len( lesions ) == 1: arr = nib.load( lesions[0] ).get_fdata()
    else: print( f'Error No Mask Found in {path}' )
    arr = preprocessing_all( arr )
    arr = arr.astype( np.bool_ )

    if idx < train_size:
        train_y.append( arr )
    elif idx < validation_size + train_size:
        val_y.append( arr )
    else:
        test_y.append( arr )

train_x, train_y = np.asarray( train_x ), np.asarray( train_y )
val_x, val_y = np.asarray( val_x ), np.asarray( val_y )
test_x, test_y = np.asarray( test_x ), np.asarray( test_y )


def Reshape2D( arr, size, img_size ):
    return arr.reshape( ( size*img_size, img_size, img_size ) )

# train
train_x = Reshape2D( train_x, train_size, img_size )
train_y = Reshape2D( train_y, train_size, img_size )
# validation
val_x = Reshape2D( val_x, validation_size, img_size )
val_y = Reshape2D( val_y, validation_size, img_size )
# test
test_x = Reshape2D( test_x, test_size, img_size )
test_y = Reshape2D( test_y, test_size, img_size )

# train
train_x = np.array( [ preprocessing_mri( xi ) for xi in train_x ] )
# validation
val_x = np.array( [ preprocessing_mri( xi ) for xi in val_x ] )
# test
test_x = np.array( [ preprocessing_mri( xi ) for xi in test_x ] )


train_x = np.expand_dims( train_x, -1 )
train_y = np.expand_dims( train_y, -1 )

val_x = np.expand_dims( val_x, -1 )
val_y = np.expand_dims( val_y, -1 )

test_x = np.expand_dims( test_x, -1 )
test_y = np.expand_dims( test_y, -1 )



# save
np.save( drive_dir + '/data/' + 'train_x.npy', train_x )
np.save( drive_dir + '/data/' + 'train_y.npy', train_y )

np.save( drive_dir + '/data/' + 'val_x.npy', val_x )
np.save( drive_dir + '/data/' + 'val_y.npy', val_y )

np.save( drive_dir + '/data/' + 'test_x.npy', test_x )
np.save( drive_dir + '/data/' + 'test_y.npy', test_y )
